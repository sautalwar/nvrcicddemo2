{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3671fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Libraries imported successfully\n",
      "ğŸ“… Training started at: 2026-01-09 10:25:37.314399\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "print(\"âœ… Libraries imported successfully today at:\", datetime.now())\n",
    "print(f\"ğŸ“… Training started at: {datetime.now()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07782b1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ Loading data from Lakehouse...\n",
      "âœ… Loaded from local CSV file\n",
      "âœ… Loaded 100 customer records\n",
      "\n",
      "ğŸ“Š Dataset shape: (100, 7)\n",
      "\n",
      "ğŸ¯ Churn distribution:\n",
      "churn\n",
      "0    69\n",
      "1    31\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load training data from Lakehouse\n",
    "print(\"ğŸ“‚ Loading data from Lakehouse...\")\n",
    "\n",
    "# Local execution: read from CSV directly\n",
    "# Fabric execution: use spark.read (uncomment lines below when running in Fabric)\n",
    "try:\n",
    "    # Try Fabric/Spark approach first\n",
    "    data = spark.read.format(\"csv\") \\\n",
    "        .option(\"header\", \"true\") \\\n",
    "        .option(\"inferSchema\", \"true\") \\\n",
    "        .load(\"Files/silver/customer_features/sample_customer_data.csv\") \\\n",
    "        .toPandas()\n",
    "    print(\"âœ… Loaded from Fabric Lakehouse via Spark\")\n",
    "except:\n",
    "    # Fallback to local CSV file (go up one directory from notebooks/)\n",
    "    data = pd.read_csv(\"../sample_customer_data.csv\")\n",
    "    print(\"âœ… Loaded from local CSV file\")\n",
    "\n",
    "print(f\"âœ… Loaded {len(data)} customer records\")\n",
    "print(f\"\\nğŸ“Š Dataset shape: {data.shape}\")\n",
    "print(f\"\\nğŸ¯ Churn distribution:\\n{data['churn'].value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d869f28b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”§ Engineering features...\n",
      "âœ… Features prepared: 8 features\n"
     ]
    }
   ],
   "source": [
    "# Feature engineering\n",
    "print(\"ğŸ”§ Engineering features...\")\n",
    "\n",
    "# âš ï¸ INTENTIONAL ERROR: Division by zero when customer_age_days is 0\n",
    "data['purchase_frequency'] = data['total_purchases'] / (data['customer_age_days'] / 30)\n",
    "data['engagement_score'] = (data['total_purchases'] * data['avg_purchase_value']) / data['customer_age_days']\n",
    "data['recency_score'] = 1 / (data['days_since_last_purchase'] + 1)\n",
    "\n",
    "feature_columns = [\n",
    "    'total_purchases', 'avg_purchase_value', 'days_since_last_purchase',\n",
    "    'customer_age_days', 'support_tickets', 'purchase_frequency',\n",
    "    'engagement_score', 'recency_score'\n",
    "]\n",
    "\n",
    "X = data[feature_columns]\n",
    "y = data['churn']\n",
    "\n",
    "print(f\"âœ… Features prepared: {len(feature_columns)} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "42f81ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Training set: 80 samples\n",
      "ğŸ“Š Test set: 20 samples\n"
     ]
    }
   ],
   "source": [
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"ğŸ“Š Training set: {len(X_train)} samples\")\n",
    "print(f\"ğŸ“Š Test set: {len(X_test)} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9fe75777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ¤– Training Random Forest model...\n",
      "âœ… Model training completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/09 10:26:23 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Model Performance Metrics:\n",
      "========================================\n",
      "  Accuracy:  1.0000\n",
      "  Precision: 1.0000\n",
      "  Recall:    1.0000\n",
      "  F1 Score:  1.0000\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "# Model training with MLflow tracking\n",
    "print(\"\\nğŸ¤– Training Random Forest model...\")\n",
    "\n",
    "mlflow.set_experiment(\"NVR_Customer_Churn_Prediction\")\n",
    "\n",
    "with mlflow.start_run(run_name=f\"rf_model_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"):\n",
    "    # Model parameters\n",
    "    params = {\n",
    "        'n_estimators': 100,\n",
    "        'max_depth': 10,\n",
    "        'min_samples_split': 5,\n",
    "        'random_state': 42\n",
    "    }\n",
    "    \n",
    "    # Log parameters\n",
    "    mlflow.log_params(params)\n",
    "    \n",
    "    # Train model\n",
    "    model = RandomForestClassifier(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"âœ… Model training completed\")\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    # Log metrics\n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "    mlflow.log_metric(\"precision\", precision)\n",
    "    mlflow.log_metric(\"recall\", recall)\n",
    "    mlflow.log_metric(\"f1_score\", f1)\n",
    "    \n",
    "    # Log model\n",
    "    mlflow.sklearn.log_model(model, \"random_forest_model\")\n",
    "    \n",
    "    print(\"\\nğŸ“Š Model Performance Metrics:\")\n",
    "    print(\"=\" * 40)\n",
    "    print(f\"  Accuracy:  {accuracy:.4f}\")\n",
    "    print(f\"  Precision: {precision:.4f}\")\n",
    "    print(f\"  Recall:    {recall:.4f}\")\n",
    "    print(f\"  F1 Score:  {f1:.4f}\")\n",
    "    print(\"=\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "65b15cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ” Feature Importance:\n",
      "========================================\n",
      "  days_since_last_purchase       0.2225\n",
      "  customer_age_days              0.1987\n",
      "  avg_purchase_value             0.1975\n",
      "  recency_score                  0.1158\n",
      "  total_purchases                0.1025\n",
      "  support_tickets                0.0920\n",
      "  engagement_score               0.0703\n",
      "  purchase_frequency             0.0007\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "# Feature importance analysis\n",
    "print(\"\\nğŸ” Feature Importance:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_columns,\n",
    "    'importance': model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "for idx, row in feature_importance.iterrows():\n",
    "    print(f\"  {row['feature']:30s} {row['importance']:.4f}\")\n",
    "\n",
    "print(\"=\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cb6937e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Model Training Pipeline Completed\n",
      "==================================================\n",
      "  Model Type: Random Forest Classifier\n",
      "  Training Samples: 80\n",
      "  Test Samples: 20\n",
      "  Features: 8\n",
      "  Model Accuracy: 100.00%\n",
      "  Completed at: 2026-01-09 10:27:17.623769\n",
      "==================================================\n",
      "\n",
      "ğŸš€ Model ready for deployment!\n"
     ]
    }
   ],
   "source": [
    "# Model validation summary\n",
    "print(\"\\nâœ… Model Training Pipeline Completed\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"  Model Type: Random Forest Classifier\")\n",
    "print(f\"  Training Samples: {len(X_train)}\")\n",
    "print(f\"  Test Samples: {len(X_test)}\")\n",
    "print(f\"  Features: {len(feature_columns)}\")\n",
    "print(f\"  Model Accuracy: {accuracy:.2%}\")\n",
    "print(f\"  Completed at: {datetime.now()}\")\n",
    "print(\"=\" * 50)\n",
    "print(\"\\nğŸš€ Model ready for deployment!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ead2d7c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "ğŸš€ Model Training v2.0 - Enhanced Logging\n",
      "==================================================\n",
      "Training started: 2026-01-09 10:25:57.086557\n",
      "Environment: dev\n",
      "Model version: 2.0\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "# Enhanced logging for production monitoring\n",
    "print(\"=\" * 50)\n",
    "print(\"ğŸš€ Model Training v2.0 - Enhanced Logging\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Training started: {datetime.now()}\")\n",
    "print(f\"Environment: {os.environ.get('ENVIRONMENT', 'dev')}\")\n",
    "print(f\"Model version: 2.0\")\n",
    "print(\"=\" * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
